{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harrisuddin/F20DL/blob/main/Imaging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqxS6mjEjMxJ"
      },
      "source": [
        "Chapter 10: “Hands-On Machine Learning with Scikit-Learn, Keras and TensorFlow by Aurélien Géron (O’Reilly). Copyright 2019 Aurélien Géron, 978-1-492-03264-9.”\n",
        "Code from:\n",
        "https://github.com/ageron/handson-ml2/blob/master/10_neural_nets_with_keras.ipynb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRIq50piJ79U"
      },
      "source": [
        "# Building an Image Classifier\n",
        "We will use Fashion MNIST data set. It has the exact same format as MNIST (70,000 grayscale images of 28×28 pixels each, with 10 classes), but the images represent fashion items rather than handwritten digits, so each class is more diverse and the problem turns out to be significantly more challenging than MNIST. For example, a simple linear model reaches about 92% accuracy on MNIST, but only about 83% on Fashion MNIST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdaNvUlCJCg5"
      },
      "source": [
        "import sklearn\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import requests\n",
        "import io\n",
        "import pandas as pd\n",
        "from io import BytesIO"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Lfww1AVxKAQ3",
        "outputId": "bb49f576-a604-4e60-e093-32eb133ed0f5"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.9.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QJtit54VKCfq",
        "outputId": "449bd0a1-f17e-40e9-a15f-39ddfabed40d"
      },
      "source": [
        "keras.__version__"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.9.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lk5iQcMkKJBO"
      },
      "source": [
        "Let's start by loading the fashion MNIST dataset. Keras has a number of functions to load popular datasets in keras.datasets. The dataset is already split for you between a training set and a test set, but it can be useful to split the training set further to have a validation set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7enJwG6KC5t"
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "X_url = \"https://raw.githubusercontent.com/harrisuddin/F20DL/main/smiley_X.npy\"\n",
        "y_url = \"https://raw.githubusercontent.com/harrisuddin/F20DL/main/smiley_y.npy\"\n",
        "\n",
        "#bnb_url = \"https://raw.githubusercontent.com/harrisuddin/F20DL/main/Airbnb_Open_Data.csv\"\n",
        "#bnb_download = requests.get(bnb_url).content\n",
        "\n",
        "X_download = requests.get(X_url).content\n",
        "y_download = requests.get(y_url).content\n",
        "#print(X_download)\n",
        "\n",
        "\n",
        "X = np.load(BytesIO(X_download))\n",
        "y = np.load(BytesIO(y_download))\n",
        "\n",
        "X_train_full, X_test = X, X\n",
        "y_train_full, y_test = y, y\n",
        "\n",
        "#X = np.load(X_download)\n",
        "#y = np.load(y_download)\n",
        "\n",
        "#df = pd.DataFrame(eval, X_download)"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9P1Wjv4dKQcL"
      },
      "source": [
        "When loading MNIST or Fashion MNIST using Keras rather than Scikit-Learn, one important difference is that every image is represented as a 28×28 array rather than a 1D array of size 784. Moreover, the pixel intensities are represented as integers (from 0 to 255) rather than floats (from 0.0 to 255.0). Below find  the shape and data type.\n",
        "\n",
        "The training set contains 60,000 grayscale images, each 28x28 pixels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17sidOz7KMLV",
        "outputId": "8ec6ed22-c002-410f-d2f2-aa8d5207c714"
      },
      "source": [
        "#X_train_full = X_train_full.fillna(0)\n",
        "#X_train_full = np.delete(X_train_full, 0, 3)\n",
        "#X_full = X_train_full[2]\n",
        "\n",
        "X_train_full.shape = (144, 9, 9)\n",
        "X_train_full.shape"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(144, 9, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yG4w6QKJKSLr"
      },
      "source": [
        "Each pixel intensity is represented as a byte (0 to 255):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HubZng06KO8E",
        "outputId": "a58be432-8269-4e9e-a81e-02f126b12072"
      },
      "source": [
        "X_train_full.dtype"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5RrODSJKatV"
      },
      "source": [
        "Let's split the full training set into a validation set and a (smaller) training set. We also scale the pixel intensities down to the 0-1 range and convert them to floats, by dividing by 255."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDDdbS1wKdI9"
      },
      "source": [
        "X_valid, X_train = X_train_full[:30] / 2., X_train_full[30:] / 2.\n",
        "y_valid, y_train = y_train_full[:30], y_train_full[30:]\n",
        "X_test = X_test / 2."
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojdRo0XXKfVl"
      },
      "source": [
        "You can plot an image using Matplotlib's imshow() function, with a 'binary' color map:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "KOL4Z7iQKf3H",
        "outputId": "9413ab4e-6963-4709-9d34-52817ef579bd"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "plt.imshow(X_train[0], cmap=\"binary\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAADBklEQVR4nO3cQWqEQBBA0VTw/lfurMM0uOr4I+8tR9CG8VPgomat9QX0fD99AGBPnBAlTogSJ0SJE6Kum+s+5cJ5s/vR5IQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROiricfPjNH77/WOnr/N/AfdJmcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IWpulv7aCAznbTd7m5wQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFC1PX0AU6a2a4D5WVudi//WyYnRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcEPXo3trTe2Xfus+U3976HpmcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQtTc7OS0+BXO2y7eNTkhSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFC1HVzff7kFMAHkxOixAlR4oQocUKUOCFKnBD1Ay7UHM7lTQAxAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAtVLmBcKhnU"
      },
      "source": [],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "083D4WUZKkk3"
      },
      "source": [
        "The labels are the class IDs (represented as uint8), from 0 to 9:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQPSAG_tKlEM",
        "outputId": "a0a77f77-eeb7-4cec-b35e-3f6fb466cb37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_train"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
              "       1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
              "       1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R38BlDeKmmn"
      },
      "source": [
        "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTFc86-5Kn5q",
        "outputId": "a8decc0d-4408-4711-c3ff-0720e691f4c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        }
      },
      "source": [
        "class_names[y_train[0]]"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-158-8b713e15d18f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclass_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not numpy.float64"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0W85ihUKrD_"
      },
      "source": [
        "The validation set contains 5,000 images, and the test set contains 10,000 images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zmz03n50Krd8"
      },
      "source": [
        "X_valid.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGaagnT1KstJ"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Jubm7cYKwlC"
      },
      "source": [
        "Let's take a look at a sample of the images in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HWfsaTOKw_o"
      },
      "source": [
        "n_rows = 4\n",
        "n_cols = 10\n",
        "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
        "for row in range(n_rows):\n",
        "    for col in range(n_cols):\n",
        "        index = n_cols * row + col\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
        "        plt.axis('off')\n",
        "        plt.title(class_names[y_train[index]], fontsize=12)\n",
        "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmTxxVJzpxU1"
      },
      "source": [
        "Let’s build the neural network! Here is a classification MLP with two hidden layers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64ccxQjOK0C3"
      },
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[28, 28])) # first layer convert each input image into a 1D array\n",
        "model.add(keras.layers.Dense(300, activation=\"relu\")) #hidden layer with 300 neurons useing the ReLU activation function.\n",
        "model.add(keras.layers.Dense(100, activation=\"relu\")) #hidden layer with 100 neurons using the ReLU\n",
        "\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\")) #output layer with 10 neurons (one per class), using the softmax "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEL9o15XK4Il"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OOHGZiHr7VZ"
      },
      "source": [
        "You can also pass a list of layers when creating the Sequential model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZYkgs59K6aR"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTGu6Ov-LAWk"
      },
      "source": [
        "model.layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUcaGnctLFlU"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ve4YbzUsbZm"
      },
      "source": [
        "summary() method displays all the model’s layers including each layer’s name (which is automatically generated unless you set it when creating the layer), its output shape (None means the batch size can be anything), and its number of parameters. The summary ends with the total number of parameters, including trainable and non-trainable parameters. How many non-trainable parameters ?\n",
        "You can also generate an image of your model using keras.utils.plot_model()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTzkbTPaLG9e"
      },
      "source": [
        "keras.utils.plot_model(model, \"my_fashion_mnist_model.png\", show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O9ATphVtHfG"
      },
      "source": [
        "Below you can dispaly differnt layer type and parameters values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OscR5b9FLIu1"
      },
      "source": [
        "hidden1 = model.layers[1]\n",
        "hidden1.name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKP0hQsELLHD"
      },
      "source": [
        "model.get_layer(hidden1.name) is hidden1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im06WP6lLNE3"
      },
      "source": [
        "weights, biases = hidden1.get_weights()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1uQ2rTcLOqZ"
      },
      "source": [
        "weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDeZNCclLQI4"
      },
      "source": [
        "weights.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5TUtU5XLSbF"
      },
      "source": [
        "biases"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqYuKGkLLT3Q"
      },
      "source": [
        "biases.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkT7hxSJtbCv"
      },
      "source": [
        "After a model is created, you must call its compile() method to specify the loss function and the optimizer (i.e learning rule) to use. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqjK1NleLaBv"
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"sgd\", #\"sgd\" simply means that we will train the model using simple Stochastic Gradient Descent\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BCsMRiaLeCA"
      },
      "source": [
        "This is equivalent to:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiTyssKpLe8B"
      },
      "source": [
        "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.SGD(), #\"sgd\" simply means that we will train the model using simple Stochastic Gradient Descent\n",
        "              metrics=[keras.metrics.sparse_categorical_accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2s0mu2dtzP8"
      },
      "source": [
        "We use the \"sparse_categorical_crossen tropy\" loss because we have sparse labels (i.e., for each instance there is just a target class index, from 0 to 9 in this case), and the classes are exclusive. If instead we had one target probability per class for each instance (such as one-hot vectors, e.g. [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.] to represent class 3), then we would need to use the \"categorical_crossentropy\" loss instead. If we were doing binary classi‐ fication (with one or more binary labels), then we would use the \"sigmoid\" (i.e., logistic) activation function in the output layer instead of the \"softmax\" activation function, and we would use the \"binary_crossentropy\" loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApjRdSFFurrB"
      },
      "source": [
        "Below we train the model; so we call the  fit() method. We pass it the input features (X_train) and the target classes (y_train), as well as the number of epochs to train "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAZ6oYKGLhEi"
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=30,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOaqW_TYvQGG"
      },
      "source": [
        "Finished training your network in 30 iterations. At each epoch during training, Keras displays the number of instances processed so far (along with a progress bar), the mean training time per sample, the loss and accuracy (or any other extra metrics you asked for), both on the training set and the validation set. You can see that the training loss went down, which is a good sign, and the validation accuracy reached 88.88% after 30 epochs, not too far from the training accuracy, so there does not seem to be much overfitting going on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLfXehYVLkct"
      },
      "source": [
        "history.params # fit method returns History object; which contains the training parameters (history.params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6Ss-k9QRvLI"
      },
      "source": [
        "print(history.epoch) # list of epochs it went through (history.epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kla1mQ7_Rw1x"
      },
      "source": [
        "history.history.keys() # contains the  metrics measured at the end of each epoch on the training set and on the validation set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UGIWdsiyAd7"
      },
      "source": [
        "plot() method, plots learning curves ( accuracy, loss on validation and training against the epochs)\n",
        "By inspecting your learning curve, you can see how well your classifier is learning abd wether you have overfitting. Comment on the figure below.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkI7YeIkRypw"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1m_E3IR5R063"
      },
      "source": [
        "model.evaluate(X_test, y_test) # now finally time to evaluate your model on the testing set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAcyoeTAzg-V"
      },
      "source": [
        "Are you happy with the results on your test set? If not, what would be you do?\n",
        "What can you say about your generalization error?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voIetP2uR3GK"
      },
      "source": [
        "X_new = X_test[:3] # make predictions on  first 3 instances of the test set \n",
        "y_proba = model.predict(X_new)\n",
        "y_proba.round(2) # For each instance the model estimates one probability per class, from class 0 to class 9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwSjm0NMR5KU"
      },
      "source": [
        "y_pred = np.argmax(model.predict(X_new), axis=-1)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx9Ami3eR8af"
      },
      "source": [
        "np.array(class_names)[y_pred]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNIYkxg6R-K9"
      },
      "source": [
        "y_new = y_test[:3]\n",
        "y_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C54UoQSHSAOe"
      },
      "source": [
        "plt.figure(figsize=(7.2, 2.4))\n",
        "for index, image in enumerate(X_new):\n",
        "    plt.subplot(1, 3, index + 1)\n",
        "    plt.imshow(image, cmap=\"binary\", interpolation=\"nearest\")\n",
        "    plt.axis('off')\n",
        "    plt.title(class_names[y_test[index]], fontsize=12)\n",
        "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNlYEbm1SC1f"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}